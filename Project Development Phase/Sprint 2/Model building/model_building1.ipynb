{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#FOR BODY DAMAGE\n",
        "\n",
        "#IMAGE PRE PROCESSING\n",
        "\n",
        "#1. Import The ImageDataGenerator Library\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#2. Configure ImageDataGenerator Class\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.1,\n",
        "                                   zoom_range = 0.1,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "#3. Apply ImageDataGenerator Functionality To Trainset And Testset\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/training',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/validation',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 10,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "#MODEL BUILDING\n",
        "\n",
        "#1. Importing The Model Building Libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#2. Loading The Model\n",
        "\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/training'\n",
        "valid_path = '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/validation'\n",
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "#3. Adding Flatten Layer\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "folders = glob('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/training/*')\n",
        "folders\n",
        "['/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/training/02-side',\n",
        " '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/training/00-front',\n",
        " '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/training/01-rear']\n",
        "x = Flatten()(vgg16.output)\n",
        "len(folders)\n",
        "3\n",
        "#4. Adding Output Layer\n",
        "\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "#5. Creating A Model Object\n",
        "\n",
        "model = Model(inputs=vgg16.input, outputs=prediction)\n",
        "model.summary()\n",
        "Model: \"model\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
        "                                                                 \n",
        " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
        "                                                                 \n",
        " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
        "                                                                 \n",
        " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
        "                                                                 \n",
        " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
        "                                                                 \n",
        " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
        "                                                                 \n",
        " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
        "                                                                 \n",
        " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
        "                                                                 \n",
        " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
        "                                                                 \n",
        " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
        "                                                                 \n",
        " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
        "                                                                 \n",
        " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
        "                                                                 \n",
        " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
        "                                                                 \n",
        " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
        "                                                                 \n",
        " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
        "                                                                 \n",
        " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
        "                                                                 \n",
        " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
        "                                                                 \n",
        " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
        "                                                                 \n",
        " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
        "                                                                 \n",
        " flatten (Flatten)           (None, 25088)             0         \n",
        "                                                                 \n",
        " dense (Dense)               (None, 3)                 75267     \n",
        "                                                                 \n",
        "=================================================================\n",
        "Total params: 14,789,955\n",
        "Trainable params: 75,267\n",
        "Non-trainable params: 14,714,688\n",
        "_________________________________________________________________\n",
        "#6. Configure The Learning Process\n",
        "\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "#7. Train The Model\n",
        "\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=25,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")\n",
        "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
        "  \n",
        "Epoch 1/25\n",
        "98/98 [==============================] - 606s 6s/step - loss: 1.2827 - accuracy: 0.5649 - val_loss: 0.8292 - val_accuracy: 0.7076\n",
        "Epoch 2/25\n",
        "98/98 [==============================] - 601s 6s/step - loss: 0.6301 - accuracy: 0.7467 - val_loss: 1.2482 - val_accuracy: 0.5965\n",
        "Epoch 3/25\n",
        "98/98 [==============================] - 601s 6s/step - loss: 0.5073 - accuracy: 0.8039 - val_loss: 0.8174 - val_accuracy: 0.7193\n",
        "Epoch 4/25\n",
        "98/98 [==============================] - 601s 6s/step - loss: 0.3564 - accuracy: 0.8621 - val_loss: 0.9245 - val_accuracy: 0.6608\n",
        "Epoch 5/25\n",
        "98/98 [==============================] - 599s 6s/step - loss: 0.2951 - accuracy: 0.8917 - val_loss: 1.9934 - val_accuracy: 0.5906\n",
        "Epoch 6/25\n",
        "98/98 [==============================] - 638s 7s/step - loss: 0.2557 - accuracy: 0.9152 - val_loss: 0.9176 - val_accuracy: 0.6842\n",
        "Epoch 7/25\n",
        "98/98 [==============================] - 607s 6s/step - loss: 0.2083 - accuracy: 0.9367 - val_loss: 0.9594 - val_accuracy: 0.7018\n",
        "Epoch 8/25\n",
        "98/98 [==============================] - 600s 6s/step - loss: 0.2184 - accuracy: 0.9122 - val_loss: 1.0329 - val_accuracy: 0.6784\n",
        "Epoch 9/25\n",
        "98/98 [==============================] - 602s 6s/step - loss: 0.1320 - accuracy: 0.9581 - val_loss: 1.0539 - val_accuracy: 0.7135\n",
        "Epoch 10/25\n",
        "98/98 [==============================] - 599s 6s/step - loss: 0.1131 - accuracy: 0.9622 - val_loss: 1.2113 - val_accuracy: 0.6842\n",
        "Epoch 11/25\n",
        "98/98 [==============================] - 597s 6s/step - loss: 0.1001 - accuracy: 0.9745 - val_loss: 0.9917 - val_accuracy: 0.7018\n",
        "Epoch 12/25\n",
        "98/98 [==============================] - 598s 6s/step - loss: 0.0954 - accuracy: 0.9745 - val_loss: 1.0601 - val_accuracy: 0.7018\n",
        "Epoch 13/25\n",
        "98/98 [==============================] - 594s 6s/step - loss: 0.0695 - accuracy: 0.9816 - val_loss: 1.3700 - val_accuracy: 0.6433\n",
        "Epoch 14/25\n",
        "98/98 [==============================] - 599s 6s/step - loss: 0.1414 - accuracy: 0.9653 - val_loss: 1.1607 - val_accuracy: 0.6667\n",
        "Epoch 15/25\n",
        "98/98 [==============================] - 600s 6s/step - loss: 0.0905 - accuracy: 0.9796 - val_loss: 1.4014 - val_accuracy: 0.6667\n",
        "Epoch 16/25\n",
        "98/98 [==============================] - 601s 6s/step - loss: 0.0797 - accuracy: 0.9775 - val_loss: 1.6741 - val_accuracy: 0.6491\n",
        "Epoch 17/25\n",
        "98/98 [==============================] - 602s 6s/step - loss: 0.1042 - accuracy: 0.9745 - val_loss: 1.2824 - val_accuracy: 0.6959\n",
        "Epoch 18/25\n",
        "98/98 [==============================] - 600s 6s/step - loss: 0.0831 - accuracy: 0.9785 - val_loss: 1.1667 - val_accuracy: 0.6901\n",
        "Epoch 19/25\n",
        "98/98 [==============================] - 603s 6s/step - loss: 0.0826 - accuracy: 0.9704 - val_loss: 1.3747 - val_accuracy: 0.6374\n",
        "Epoch 20/25\n",
        "98/98 [==============================] - 600s 6s/step - loss: 0.0536 - accuracy: 0.9837 - val_loss: 1.2074 - val_accuracy: 0.6550\n",
        "Epoch 21/25\n",
        "98/98 [==============================] - 597s 6s/step - loss: 0.0716 - accuracy: 0.9796 - val_loss: 1.5491 - val_accuracy: 0.6725\n",
        "Epoch 22/25\n",
        "98/98 [==============================] - 599s 6s/step - loss: 0.0457 - accuracy: 0.9918 - val_loss: 1.2930 - val_accuracy: 0.7135\n",
        "Epoch 23/25\n",
        "98/98 [==============================] - 601s 6s/step - loss: 0.0526 - accuracy: 0.9928 - val_loss: 1.2576 - val_accuracy: 0.6959\n",
        "Epoch 24/25\n",
        "98/98 [==============================] - 601s 6s/step - loss: 0.0421 - accuracy: 0.9908 - val_loss: 1.3347 - val_accuracy: 0.7193\n",
        "Epoch 25/25\n",
        "98/98 [==============================] - 597s 6s/step - loss: 0.0597 - accuracy: 0.9826 - val_loss: 1.4728 - val_accuracy: 0.6725\n",
        "#8. Save The Model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Model/body.h5')\n",
        "#9. Test The Model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "model = load_model('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Model/body.h5')\n",
        "def detect(frame):\n",
        "  img = cv2.resize(frame,(224,224))\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if(np.max(img)>1):\n",
        "    img = img/255.0\n",
        "  img = np.array([img])\n",
        "  prediction = model.predict(img)\n",
        "  label = [\"front\",\"rear\",\"side\"]\n",
        "  preds = label[np.argmax(prediction)]\n",
        "  return preds\n",
        "import numpy as np\n",
        "data = \"/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/body/training/00-front/0005.JPEG\"\n",
        "image = cv2.imread(data)\n",
        "print(detect(image))\n",
        "\n",
        "#FOR LEVEL DAMAGE\n",
        "\n",
        "#IMAGE PRE PROCESSING\n",
        "\n",
        "#1. Import The ImageDataGenerator Library\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "#2. Configure ImageDataGenerator Class\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.1,\n",
        "                                   zoom_range = 0.1,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "#3. Apply ImageDataGenerator Functionality To Trainset And Testset\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/training',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 10,\n",
        "                                                 class_mode = 'categorical')\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/validation',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 10,\n",
        "                                            class_mode = 'categorical')\n",
        "Found 979 images belonging to 3 classes.\n",
        "Found 171 images belonging to 3 classes.\n",
        "#MODEL BUILDING\n",
        "\n",
        "#1. Importing The Model Building Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "#2. Loading The Model\n",
        "\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/training'\n",
        "valid_path = '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/validation'\n",
        "vgg16 = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "#3. Adding Flatten Layer\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "folders = glob('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/training/*')\n",
        "folders\n",
        "['/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/training/02-moderate',\n",
        " '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/training/03-severe',\n",
        " '/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/training/01-minor']\n",
        "x = Flatten()(vgg16.output)\n",
        "len(folders)\n",
        "3\n",
        "#4. Adding Output Layer\n",
        "\n",
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "#5. Creating A Model Object\n",
        "\n",
        "model = Model(inputs=vgg16.input, outputs=prediction)\n",
        "model.summary()\n",
        "Model: \"model\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
        "                                                                 \n",
        " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
        "                                                                 \n",
        " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
        "                                                                 \n",
        " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
        "                                                                 \n",
        " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
        "                                                                 \n",
        " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
        "                                                                 \n",
        " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
        "                                                                 \n",
        " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
        "                                                                 \n",
        " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
        "                                                                 \n",
        " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
        "                                                                 \n",
        " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
        "                                                                 \n",
        " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
        "                                                                 \n",
        " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
        "                                                                 \n",
        " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
        "                                                                 \n",
        " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
        "                                                                 \n",
        " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
        "                                                                 \n",
        " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
        "                                                                 \n",
        " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
        "                                                                 \n",
        " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
        "                                                                 \n",
        " flatten (Flatten)           (None, 25088)             0         \n",
        "                                                                 \n",
        " dense (Dense)               (None, 3)                 75267     \n",
        "                                                                 \n",
        "=================================================================\n",
        "Total params: 14,789,955\n",
        "Trainable params: 75,267\n",
        "Non-trainable params: 14,714,688\n",
        "_________________________________________________________________\n",
        "#6. Configure The Learning Process\n",
        "\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "7. Train The Model\n",
        "\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=25,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")\n",
        "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
        "  \n",
        "Epoch 1/25\n",
        "98/98 [==============================] - 615s 6s/step - loss: 1.2465 - accuracy: 0.5516 - val_loss: 1.0659 - val_accuracy: 0.5731\n",
        "Epoch 2/25\n",
        "98/98 [==============================] - 604s 6s/step - loss: 0.6654 - accuracy: 0.7549 - val_loss: 1.0368 - val_accuracy: 0.6316\n",
        "Epoch 3/25\n",
        "98/98 [==============================] - 604s 6s/step - loss: 0.5950 - accuracy: 0.7630 - val_loss: 1.1309 - val_accuracy: 0.6257\n",
        "Epoch 4/25\n",
        "98/98 [==============================] - 601s 6s/step - loss: 0.4964 - accuracy: 0.8069 - val_loss: 1.1262 - val_accuracy: 0.6082\n",
        "Epoch 5/25\n",
        "98/98 [==============================] - 603s 6s/step - loss: 0.3559 - accuracy: 0.8672 - val_loss: 1.1408 - val_accuracy: 0.6316\n",
        "Epoch 6/25\n",
        "98/98 [==============================] - 604s 6s/step - loss: 0.2425 - accuracy: 0.9152 - val_loss: 1.1566 - val_accuracy: 0.5789\n",
        "Epoch 7/25\n",
        "98/98 [==============================] - 604s 6s/step - loss: 0.1964 - accuracy: 0.9367 - val_loss: 1.1200 - val_accuracy: 0.6199\n",
        "Epoch 8/25\n",
        "98/98 [==============================] - 598s 6s/step - loss: 0.2119 - accuracy: 0.9203 - val_loss: 1.1181 - val_accuracy: 0.6316\n",
        "Epoch 9/25\n",
        "98/98 [==============================] - 597s 6s/step - loss: 0.1111 - accuracy: 0.9622 - val_loss: 1.3554 - val_accuracy: 0.5614\n",
        "Epoch 10/25\n",
        "98/98 [==============================] - 595s 6s/step - loss: 0.1394 - accuracy: 0.9438 - val_loss: 1.2256 - val_accuracy: 0.6082\n",
        "Epoch 11/25\n",
        "98/98 [==============================] - 598s 6s/step - loss: 0.1167 - accuracy: 0.9602 - val_loss: 1.3020 - val_accuracy: 0.6374\n",
        "Epoch 12/25\n",
        "98/98 [==============================] - 598s 6s/step - loss: 0.0823 - accuracy: 0.9755 - val_loss: 1.3000 - val_accuracy: 0.6550\n",
        "Epoch 13/25\n",
        "98/98 [==============================] - 602s 6s/step - loss: 0.1062 - accuracy: 0.9632 - val_loss: 1.2962 - val_accuracy: 0.6433\n",
        "Epoch 14/25\n",
        "98/98 [==============================] - 599s 6s/step - loss: 0.0717 - accuracy: 0.9775 - val_loss: 1.3089 - val_accuracy: 0.6491\n",
        "Epoch 15/25\n",
        "98/98 [==============================] - 598s 6s/step - loss: 0.0692 - accuracy: 0.9826 - val_loss: 1.2885 - val_accuracy: 0.6023\n",
        "Epoch 16/25\n",
        "98/98 [==============================] - 595s 6s/step - loss: 0.0449 - accuracy: 0.9898 - val_loss: 1.7932 - val_accuracy: 0.5673\n",
        "Epoch 17/25\n",
        "98/98 [==============================] - 609s 6s/step - loss: 0.0522 - accuracy: 0.9867 - val_loss: 1.2697 - val_accuracy: 0.6433\n",
        "Epoch 18/25\n",
        "98/98 [==============================] - 607s 6s/step - loss: 0.0386 - accuracy: 0.9969 - val_loss: 1.5100 - val_accuracy: 0.6023\n",
        "Epoch 19/25\n",
        "98/98 [==============================] - 595s 6s/step - loss: 0.0381 - accuracy: 0.9939 - val_loss: 1.2199 - val_accuracy: 0.6784\n",
        "Epoch 20/25\n",
        "98/98 [==============================] - 596s 6s/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 1.2907 - val_accuracy: 0.6433\n",
        "Epoch 21/25\n",
        "98/98 [==============================] - 597s 6s/step - loss: 0.0394 - accuracy: 0.9928 - val_loss: 1.2678 - val_accuracy: 0.6491\n",
        "Epoch 22/25\n",
        "98/98 [==============================] - 595s 6s/step - loss: 0.0377 - accuracy: 0.9908 - val_loss: 1.4709 - val_accuracy: 0.6316\n",
        "Epoch 23/25\n",
        "98/98 [==============================] - 595s 6s/step - loss: 0.0387 - accuracy: 0.9918 - val_loss: 1.3320 - val_accuracy: 0.6257\n",
        "Epoch 24/25\n",
        "98/98 [==============================] - 596s 6s/step - loss: 0.0279 - accuracy: 0.9949 - val_loss: 1.6355 - val_accuracy: 0.6433\n",
        "Epoch 25/25\n",
        "98/98 [==============================] - 603s 6s/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 1.3182 - val_accuracy: 0.6608\n",
        "#8. Save The Model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Model/level.h5')\n",
        "#9. Test The Model\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "model = load_model('/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Model/level.h5')\n",
        "def detect(frame):\n",
        "  img = cv2.resize(frame,(224,224))\n",
        "  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  if(np.max(img)>1):\n",
        "    img = img/255.0\n",
        "  img = np.array([img])\n",
        "  prediction = model.predict(img)\n",
        "  label = [\"minor\",\"moderate\",\"severe\"]\n",
        "  preds = label[np.argmax(prediction)]\n",
        "  return preds\n",
        "import numpy as np\n",
        "data = \"/content/drive/MyDrive/Intelligent Vehicle Damage Assessment & Cost Estimator For Insurance Companies/Dataset/level/validation/01-minor/0010.JPEG\"\n",
        "image = cv2.imread(data)\n",
        "print(detect(image))\n",
        "  File \"\", line 69\n",
        "    Layer (type)                Output Shape              Param #\n",
        "    ^\n",
        "IndentationError: unexpected indent"
      ],
      "metadata": {
        "id": "Xu6fL6DcTLqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HPVCsf6DTMDU"
      }
    }
  ]
}